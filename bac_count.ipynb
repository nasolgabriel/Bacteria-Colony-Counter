{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce GTX 1660 SUPER\n",
      "\u001b[2K\n",
      "\u001b[2K\n",
      "Ultralytics YOLOv8.2.66 ðŸš€ Python-3.12.2 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "Setup complete âœ… (4 CPUs, 15.9 GB RAM, 277.4/476.4 GB disk)\n",
      "\n",
      "OS                  Windows-10-10.0.19045-SP0\n",
      "Environment         Windows\n",
      "Python              3.12.2\n",
      "Install             git\n",
      "RAM                 15.92 GB\n",
      "CPU                 AMD Ryzen 3 2200G with Radeon Vega Graphics\n",
      "CUDA                11.8\n",
      "\n",
      "numpy               âœ… 1.26.3<2.0.0,>=1.23.0\n",
      "matplotlib          âœ… 3.9.1>=3.3.0\n",
      "opencv-python       âœ… 4.10.0.84>=4.6.0\n",
      "pillow              âœ… 10.2.0>=7.1.2\n",
      "pyyaml              âœ… 6.0.1>=5.3.1\n",
      "requests            âœ… 2.32.3>=2.23.0\n",
      "scipy               âœ… 1.14.0>=1.4.1\n",
      "torch               âœ… 2.3.1+cu118>=1.8.0\n",
      "torchvision         âœ… 0.18.1+cu118>=0.9.0\n",
      "tqdm                âœ… 4.66.4>=4.64.0\n",
      "psutil              âœ… 6.0.0\n",
      "py-cpuinfo          âœ… 9.0.0\n",
      "pandas              âœ… 2.2.2>=1.1.4\n",
      "seaborn             âœ… 0.13.2>=0.11.0\n",
      "ultralytics-thop    âœ… 2.0.0>=2.0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "!yolo checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from ultralytics import YOLO\n",
    "from IPython import display\n",
    "display.clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # COMMENTED BECAUSE TRAINING STARTED\n",
    "\n",
    "# model = YOLO(\"yolov8n.yaml\")  # build a new model from YAML. if \"pt\" the model is pre-trained\n",
    "\n",
    "# # Train the model\n",
    "# results = model.train(data=\"validation_testing_etc/Train_Test_Split/dataset_train-test/data.yaml\", \n",
    "#                       epochs=50, imgsz=608,patience=10, plots=True, batch=8, cache='ram', amp=False, cos_lr=True, lr0=0.001, lrf=0.001,                # MODEL PARAM\n",
    "#                       hsv_s=0.90, hsv_h=0.30, hsv_v=0.60, shear=2.0, flipud=0.25, fliplr=0.25, bgr=0.25, mixup=0.25, degrees=90.0, copy_paste=0.15,    # AUGMENTATION\n",
    "#                       dropout=0.15,\n",
    "#                       single_cls= True, device='0', project='runs/detect/', name=\"608px-50_epoch-yolon-augment\")                                       # LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8s.yaml\")  # build a new model from YAML. if \"pt\" the model is pre-trained\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"validation_testing_etc/Train_Test_Split/dataset_train-test/data.yaml\", \n",
    "                      epochs=100, imgsz=608,patience=10, plots=True, batch=6, cache='ram', amp=False, cos_lr=True, lr0=0.01, lrf=0.001,               # MODEL PARAM\n",
    "                      hsv_s=0.75, hsv_h=0.50, hsv_v=0.60, shear=2.0, flipud=0.25, fliplr=0.25, bgr=0.25, mixup=0.10, degrees=90.0, copy_paste=0.15,    # AUGMENTATION\n",
    "                      dropout=0.20,\n",
    "                      single_cls= True, device='0', project='runs/detect/', name=\"608px-100_epoch-yolos-augment\")                                       # LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # RESUMING TRAINING\n",
    "# Directory containing the checkpoint files\n",
    "model = YOLO('runs/detect/608px-100_epoch-yolos-augment-pre-trained2/weights/last.pt')\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"validation_testing_etc/Train_Test_Split/dataset_train-test/data.yaml\", resume=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Command to shut down the PC after the code execution\n",
    "os.system(\"shutdown /s /t 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VALIDATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.66  Python-3.12.2 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "YOLOv8s summary (fused): 168 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\repos\\python\\Bacteria_counter\\validation_testing_etc\\Train_Test_Split\\dataset_train-test\\val\\labels.cache... 1322 images, 81 backgrounds, 4 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1322/1322 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\repos\\python\\Bacteria_counter\\validation_testing_etc\\Train_Test_Split\\dataset_train-test\\val\\images\\12607.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0059      1.0006]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\repos\\python\\Bacteria_counter\\validation_testing_etc\\Train_Test_Split\\dataset_train-test\\val\\images\\3440.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0128]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\repos\\python\\Bacteria_counter\\validation_testing_etc\\Train_Test_Split\\dataset_train-test\\val\\images\\4089.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0168]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\repos\\python\\Bacteria_counter\\validation_testing_etc\\Train_Test_Split\\dataset_train-test\\val\\images\\7921.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0097]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83/83 [01:14<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1318      29732      0.964      0.874      0.931      0.614\n",
      "Speed: 0.6ms preprocess, 10.0ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val2\u001b[0m\n",
      "mAP@0.5:0.95: 0.6137656229455193\n",
      "mAP@0.5: 0.930880394314191\n",
      "mAP@0.75: 0.7073958538912994\n",
      "mAP@0.5:0.95 for class 0: 0.6137656229455193\n",
      "Class 0: Precision: 0.9642671614100186, Recall: 0.8740414368357325, F1 Score: 0.9169401220846124\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"runs/detect/608px-100_epoch-yolos-augment(BEST)/weights/best.pt\")\n",
    "\n",
    "# Run validation\n",
    "metrics = model.val(plots=True, imgsz=608, batch=16, conf=0.30, iou=0.6, device=\"0\", project='runs/detect/', rect=True)\n",
    "\n",
    "# Access and print various metrics\n",
    "print(f\"mAP@0.5:0.95: {metrics.box.map}\")  # mAP@0.5:0.95\n",
    "print(f\"mAP@0.5: {metrics.box.map50}\")    # mAP@0.5\n",
    "print(f\"mAP@0.75: {metrics.box.map75}\")   # mAP@0.75\n",
    "\n",
    "# Print mAP@0.5:0.95 for each category\n",
    "for i, map_per_class in enumerate(metrics.box.maps):\n",
    "    print(f\"mAP@0.5:0.95 for class {i}: {map_per_class}\")\n",
    "\n",
    "# Access precision, recall, and F1 score for each class\n",
    "precision = metrics.box.p\n",
    "recall = metrics.box.r\n",
    "f1 = metrics.box.f1\n",
    "\n",
    "# Print precision, recall, and F1 score for each class\n",
    "for i in range(len(precision)):\n",
    "    print(f\"Class {i}: Precision: {precision[i]}, Recall: {recall[i]}, F1 Score: {f1[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREDICTION** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\repos\\python\\Bacteria_counter\\validation_testing_etc\\Train_Test_Split\\dataset_train-test\\val\\images\\3650.jpg: 608x544 23 colonys, 798.1ms\n",
      "Speed: 5.0ms preprocess, 798.1ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 544)\n"
     ]
    }
   ],
   "source": [
    "# PREDICTION\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"runs/detect/608px-100_epoch-yolos-augment-pre-trained/weights/best.pt\",)\n",
    "\n",
    "# Run batched inference on a list of images\n",
    "results = model('validation_testing_etc/Train_Test_Split/dataset_train-test/val/images/3650.jpg', conf=0.50, augment=True, stream=False, device='cpu')  # return a generator of Results objects\n",
    "\n",
    "# Process results generator\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    result.show()  # display to screen\n",
    "    # result.save(filename=\"result.jpg\")  # save to disk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\repos\\python\\Bacteria_counter\\validation_testing_etc\\Train_Test_Split\\dataset_train-test\\val\\images\\13604.jpg: 608x608 21 colonys, 23.0ms\n",
      "Speed: 5.0ms preprocess, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 608, 608)\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"runs/detect/608px-100_epoch-yolos-augment(BEST)/weights/best.pt\")  # your custom-trained YOLO model\n",
    "\n",
    "# Run inference on a single image\n",
    "results = model('validation_testing_etc/Train_Test_Split/dataset_train-test/val/images/13604.jpg')  \n",
    "\n",
    "# Function to draw bounding boxes without labels and with thinner lines\n",
    "def draw_boxes(image, boxes, thickness=50):\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Extract coordinates\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), thickness) \n",
    "    return image\n",
    "\n",
    "# Function to resize image to fit the screen\n",
    "def resize_image(image, max_width=500, max_height=500):\n",
    "    height, width = image.shape[:2]\n",
    "    scaling_factor = min(max_width / width, max_height / height)\n",
    "    new_size = (int(width * scaling_factor), int(height * scaling_factor))\n",
    "    resized_image = cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)\n",
    "    return resized_image\n",
    "\n",
    "# Process results list\n",
    "for result in results:\n",
    "    img = cv2.imread(result.path)  # Read the original image\n",
    "    img = draw_boxes(img, result.boxes, thickness=2)  # CHANGE THICKNESS HERE\n",
    "    resized_img = resize_image(img)  # Resize the image to fit the screen\n",
    "    \n",
    "    # Show the image\n",
    "    cv2.imshow('Result', resized_img)\n",
    "    cv2.waitKey(0) \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Save the image\n",
    "    output_path = \"result.jpg\"\n",
    "    cv2.imwrite(output_path, img)  # Save the image to disk\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
